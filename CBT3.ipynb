{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "https://www.tensorflow.org/tutorials/images/classification\r\n",
                "\r\n",
                "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Libraries"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import cv2\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import numpy as np\r\n",
                "import pandas as pd\r\n",
                "import os\r\n",
                "import tensorflow as tf\r\n",
                "from sklearn.metrics import plot_confusion_matrix\r\n",
                "from imblearn.under_sampling import RandomUnderSampler\r\n",
                "from imblearn.over_sampling import RandomOverSampler\r\n",
                "import seaborn as sns"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Read images"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "folders = ['PNEUMONIA', 'NORMAL']\r\n",
                "img_size = 150\r\n",
                "\r\n",
                "def get_data(data_dir):\r\n",
                "    x = []\r\n",
                "    y = []\r\n",
                "    for folder in folders:\r\n",
                "        path = os.path.join(data_dir, folder)\r\n",
                "        class_num = folders.index(folder)\r\n",
                "        for img in os.listdir(path):\r\n",
                "            try:\r\n",
                "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\r\n",
                "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\r\n",
                "                x.append(resized_arr)\r\n",
                "                y.append(class_num)\r\n",
                "            except Exception as e:\r\n",
                "                print(e)\r\n",
                "    return x,y"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "x_train, y_train = get_data('dataset/chest_xray/train')\r\n",
                "x_test, y_test  = get_data('dataset/chest_xray/test')\r\n",
                "x_val, y_val = get_data('dataset/chest_xray/val')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def dataset_count(y):\r\n",
                "    labels = []\r\n",
                "    for label in y:\r\n",
                "        if(label == 0):\r\n",
                "            labels.append(\"Pneumonia\")\r\n",
                "        else:\r\n",
                "            labels.append(\"Normal\")\r\n",
                "    print(labels.count('Pneumonia'))\r\n",
                "    sns.countplot(x=labels)\r\n",
                "\r\n",
                "dataset_count(y_train)\r\n",
                "print(len(y_train))\r\n",
                "print(len(y_test))\r\n",
                "print(len(y_val))\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def oversample(x, y):\r\n",
                "  sample = RandomOverSampler(sampling_strategy='minority')\r\n",
                "  flat = []\r\n",
                "  for image in x:\r\n",
                "    flat.append(image.flatten())\r\n",
                "  x_over , y = sample.fit_resample(flat, y)\r\n",
                "  x = []\r\n",
                "  for image in x_over:\r\n",
                "    x.append(np.array(image).reshape(150, 150))\r\n",
                "  return x, y\r\n",
                "\r\n",
                "x_train, y_train = oversample(x_train,y_train)\r\n",
                "dataset_count(y_train)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "x_train = np.array(x_train) / 255\r\n",
                "x_val = np.array(x_val) / 255\r\n",
                "x_test = np.array(x_test) / 255\r\n",
                "\r\n",
                "x_train = x_train.reshape(-1, img_size, img_size, 1)\r\n",
                "y_train = np.array(y_train)\r\n",
                "\r\n",
                "x_val = x_val.reshape(-1, img_size, img_size, 1)\r\n",
                "y_val = np.array(y_val)\r\n",
                "\r\n",
                "x_test = x_test.reshape(-1, img_size, img_size, 1)\r\n",
                "y_test = np.array(y_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
                "    rotation_range=30,\r\n",
                "    zoom_range=0.2,\r\n",
                "    width_shift_range=0.1,\r\n",
                "    height_shift_range=0.1,\r\n",
                "    horizontal_flip=True)\r\n",
                "image_generator.fit(x_train)\r\n",
                "\r\n",
                "\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model = tf.keras.models.Sequential([\r\n",
                "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(img_size, img_size, 1)),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\r\n",
                "    tf.keras.layers.BatchNormalization(),\r\n",
                "    tf.keras.layers.MaxPooling2D(),\r\n",
                "    tf.keras.layers.Flatten(),\r\n",
                "    tf.keras.layers.Dense(128, activation='relu'),\r\n",
                "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
                "])\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model.compile(optimizer='adam',\r\n",
                "              loss='binary_crossentropy',\r\n",
                "              metrics=['accuracy'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "model.summary()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "epochs = 7\r\n",
                "history = model.fit(\r\n",
                "    image_generator.flow(x_train, y_train, batch_size=32),\r\n",
                "    validation_data=image_generator.flow(x_val, y_val),\r\n",
                "    epochs=epochs\r\n",
                ")\r\n",
                "\r\n",
                "# history = model.fit(\r\n",
                "#     np.array(x_train), np.array(y_train),\r\n",
                "#     validation_data=(np.array(x_val), np.array(y_val)),\r\n",
                "#     epochs=epochs\r\n",
                "# )\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "acc = history.history['accuracy']\r\n",
                "val_acc = history.history['val_accuracy']\r\n",
                "\r\n",
                "loss = history.history['loss']\r\n",
                "val_loss = history.history['val_loss']\r\n",
                "\r\n",
                "epochs_range = range(epochs)\r\n",
                "\r\n",
                "plt.figure(figsize=(8, 8))\r\n",
                "plt.subplot(1, 2, 1)\r\n",
                "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
                "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
                "plt.legend(loc='lower right')\r\n",
                "plt.title('Training and Validation Accuracy')\r\n",
                "\r\n",
                "plt.subplot(1, 2, 2)\r\n",
                "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
                "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
                "plt.legend(loc='upper right')\r\n",
                "plt.title('Training and Validation Loss')\r\n",
                "plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "evaluate = model.evaluate(np.array(x_test), np.array(y_test))\r\n",
                "print(\"Loss of the model is - \", evaluate[0])\r\n",
                "print(\"Accuracy of the model is - \", evaluate[1]*100, \"%\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "num_classes = 2\r\n",
                "predictions = (model.predict(np.array(x_test)) > 0.5).astype(\"int32\")\r\n",
                "confusion = tf.math.confusion_matrix(labels=y_test, predictions=predictions, num_classes=num_classes)\r\n",
                "\r\n",
                "group_counts = [value for value in np.array(confusion).flatten()]\r\n",
                "group_names = ['Verdadeiro Positivo', 'Falso Positivo', 'Falso Negativo', 'Verdadeiro Negativo']\r\n",
                "group_percentages = []\r\n",
                "for index, line in enumerate(confusion):\r\n",
                "  for item in line:\r\n",
                "    group_percentages.append(item.numpy()/np.sum(line))\r\n",
                "\r\n",
                "annotations = [f'{name}\\n{round(percentage*100, 2)}%\\nQuantidade: {count}' for name, count,\r\n",
                "               percentage in zip(group_names, group_counts, group_percentages)]\r\n",
                "\r\n",
                "annotations = np.asarray(annotations).reshape(2, 2)\r\n",
                "plt.subplots(figsize=(15, 10))\r\n",
                "tick_labels = ['Sim', 'NÃ£o']\r\n",
                "sns.heatmap(confusion,  annot=annotations, fmt='', xticklabels=tick_labels, yticklabels=tick_labels)\r\n",
                "\r\n",
                "plt.xlabel(\"Detectado\")\r\n",
                "plt.ylabel(\"Real\")\r\n",
                "\r\n",
                "sns.set(font_scale=2)\r\n",
                "plt.show()\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "tf.keras.utils.plot_model(model, show_shapes=True)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit (conda)"
        },
        "interpreter": {
            "hash": "b4e07c9dc5270a724ff9979b5b8be91dddd1100a5ee5c0bc09f24c39f2642ef7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}